{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d450331-951c-40cc-baa9-114a5684ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d45aef-89b7-448c-b7f6-22649cc245c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c252f90-45d4-442f-8335-00c9c68196af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db65e6c-6f05-45f2-b893-85af91db77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_folder = \"../fonts\"\n",
    "\n",
    "fonts = glob.glob(fonts_folder + \"/*.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c03aa6-eb24-4eee-a817-2b8521c4c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(font_path: str, target: int = None) -> tuple[Image, int]:\n",
    "    color = random.randint(230, 255)\n",
    "    \n",
    "    # Generate image\n",
    "    img = Image.new(\"L\", (256, 256))\n",
    "\n",
    "    if target is None:\n",
    "        target = random.randint(0, 9)\n",
    "    \n",
    "    size = random.randint(230, 250)\n",
    "    x = random.randint(50, 70)\n",
    "    y = random.randint(15, 25)\n",
    "\n",
    "    font = ImageFont.truetype(fonts[0], size)\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((x, y), str(target), color, font=font)\n",
    "    \n",
    "    img = img.resize((28, 28), Image.BILINEAR)\n",
    "    \n",
    "    return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed975f00-8d08-4fdc-9556-5e16182f5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = generate_image(fonts[0], target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2836e7-3f31-4b0d-88a6-ea5a7e058de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACSAAST0Ar0DwZ8JNb8VwXtzOJdLtbaPcstzA371v7qg47d68/IwSPSkp8UjQypKhw6MGU+hFfSnwd8b+IPGFl4iGt3ouRbQp5WIlTbkPn7oHoK+aX++31pKK9j+BniHR9CtfEq6rqVtZmeGMRCaQLvID5xnr1FeOty5+tJRRRRX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjklEQVR4AWNgoAlgRDaViZXh329kAWS21YYtHRxIAixIbNZQP0YeZAEEm5EvMArFEgYGmKRKhJSWES+SMchMv5//weAAD5IoTOfPF2wMTEIwHlQBjHvUjZFBdL4ykjYgEyb55SYDw4efqHIMTGh8FO6oJFLwgULm55FHDJf/IoURcvQysjEy/PuFJDkQTABF7xzo0SbnxwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142c0591-dac7-4ac0-8756-4877489edb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98fca33-d1bf-4383-b3c7-5978daafdf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.axis('off') # Removes axis\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"A single cell\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec97f4d1-256c-4fc6-a16d-cea7c9f1eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f4c27f-43b8-4b05-8f68-23cf644a72de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809aaf5c931648008fb2ffe3d1958053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e04f13060e44ce839ae60a673e054c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_train = 60000\n",
    "N_val = 1000\n",
    "\n",
    "# DATASET_FOLDER = \"../data/realistic_mnist\"\n",
    "\n",
    "# Path(DATASET_FOLDER).mkdir(exist_ok=True)\n",
    "\n",
    "# Generate training set\n",
    "y_tr = []\n",
    "X_tr = []\n",
    "\n",
    "for i in trange(N_train):\n",
    "    img, target = generate_image(fonts[0])\n",
    "    X_tr.append(np.array(img).ravel())\n",
    "\n",
    "    y_tr.append(target)\n",
    "    # img_path = Path(DATASET_FOLDER) / f\"{target}_{i}.png\"\n",
    "    # img.save(img_path)\n",
    "\n",
    "X_tr = np.array(X_tr)\n",
    "y_tr = np.array(y_tr)\n",
    "\n",
    "# Sanity checks\n",
    "assert X_tr.shape == (N_train, 784)\n",
    "assert y_tr.shape == (N_train, )\n",
    "\n",
    "# Generate test set\n",
    "y_val = []\n",
    "X_val = []\n",
    "\n",
    "for i in trange(N_val):\n",
    "    img, target = generate_image(fonts[0])\n",
    "    X_val.append(np.array(img).ravel())\n",
    "\n",
    "    y_val.append(target)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Sanity checks\n",
    "assert X_val.shape == (N_val, 784)\n",
    "assert y_val.shape == (N_val, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7092d617-9e19-4c5f-90ee-43972d60ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d766f26-75eb-4270-86b4-a02c609d7772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model MLPClassifier = 100.000000%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier())])\n",
    "\n",
    "#input data normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "\n",
    "X_tr_scaled=scaler.transform(X_tr)\n",
    "X_val_scaled=scaler.transform(X_val)\n",
    "\n",
    "### TODO ###\n",
    "# Train a classifier which uses the MLPClassifier and print its accuracy\n",
    "# WARNING: use the scaled features both when training and when testing the model\n",
    "\n",
    "mlp_classifier = MLPClassifier()\n",
    "mlp_classifier.fit(X_tr_scaled, y_tr)\n",
    "y_pred = mlp_classifier.predict(X_val_scaled)\n",
    "\n",
    "print(\"Accuracy of model MLPClassifier = %2f%%\" % (accuracy_score(y_val, y_pred )*100))\n",
    "\n",
    "### END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60c07e1d-6425-48d2-83c9-12ee38cae767",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_DIR = \"../artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1003e629-11ed-4101-91a2-5728931804c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = mlp_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a15ac8c-87e2-47a6-8a89-0d3969e88a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Use pickle to save model for next usage.\n",
    "\n",
    "# Create folder if it does not exist\n",
    "Path(ARTIFACTS_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "best_model_path = Path(ARTIFACTS_DIR) / 'bestest_model_sklearn.pkl'\n",
    "with open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004f4c6-34a8-4482-a8ab-3adf452ddb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c4a6c14-b756-4600-940a-f19aa62fd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phd_school.dataset import PrintedMNIST, AddGaussianNoise, AddSPNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3e3476d-4d84-47f9-8c7b-883129214b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from timm import create_model\n",
    "from torchvision import transforms, datasets\n",
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    # AddGaussianNoise(0, 1.0),\n",
    "    AddSPNoise(0.1),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# DEFAULT_TRANSFORM = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "class LitClassification(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = create_model('resnet34', num_classes=10)\n",
    "\n",
    "\n",
    "        # Replace 1st layer to use it on grayscale images\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "            1,\n",
    "            64,\n",
    "            kernel_size=(7, 7),\n",
    "            stride=(2, 2),\n",
    "            padding=(3, 3),\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, targets = batch\n",
    "        outputs = self.model(images)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=0.005)\n",
    "    \n",
    "    \n",
    "class ClassificationData(L.LightningDataModule):\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = PrintedMNIST(320, -666, transform=train_transform)\n",
    "        \n",
    "        return torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "477862f9-4529-4d29-bfb3-07a66f851afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | ResNet           | 21.3 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.134    Total estimated model params size (MB)\n",
      "167       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c2eaeef4c94c8eb15e24d6834d5688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "model = LitClassification()\n",
    "data = ClassificationData()\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9f4b2ea-7567-4a07-b6b8-45b816bae625",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"best_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aee419-8901-467d-90e5-27f83b6d2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitClassification.load_from_checkpoint(\"best_model.ckpt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67ff97d8-9d16-4a0a-b69b-fca869d4c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = generate_image(fonts[0], target=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72f1ed69-2f7c-4f95-9982-ff4b4a531625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(val_transforms(img).unsqueeze(0))\n",
    "    _, P = torch.max(out, 1)\n",
    "\n",
    "    digit = P.item()\n",
    "    print(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "440d22b3-1d29-411d-a88f-54c0b5a7cccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6940,  1.4751, -0.5719,  0.2334,  0.8861, -0.4532, -0.3965, -0.3106,\n",
       "         -0.2303, -0.7476]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9abfdcb-4276-4338-b6df-b86ebf5d49d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "916b1f49-66e1-4aeb-b904-2a742e5d660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u/8ABHwo1vxZfqLu3udN04x+Z9rlhOG4+UKDjdmuO1rTxpOu3+nCQyC1uHhDkY3bWIzj8Ko0V7n8D/GGv6x4rOlahqc09jBYN5cLAYXaVA6DsK8o8Z/8jvrv/X/N/wChmsOivR/gprmmeH/Gs13q17FaW7WboJJTgFiy8foa4/xTcw3ni3WLm3kWSCa8leN16MpckEVkUUUUV//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4AWNgoAlgRDGVV535243fKEIIju/D5/tEEFwWBJOBQShamIEbySy4JJsgt1KcG7JSBga4pFmPgCAXki6QMrgkrxobqjZkySdLWRjYXIQxFIAFGJmYmIQOf/lyUhQhDzf2/38Ghn8IcTCLCY2Pwh2VBAYHPPhAQfNjyX6Gl99QAmlwcQAcAhV2OopJ9AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb30543-dd38-4425-bc8d-d000732d681e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
